#############################
#                           #
#     Q2Pipe Option file    #
# Designed for Q2Pipe V0.93 #
#                           #
#############################


################################
#  Common Analysis Parameters  #
################################

ANALYSIS_NAME=BASIC_TEST
NB_THREADS=8

# Leave empty if you don't use apptainer image to launch Qiime2
# To define a different temporary folder, add -B /path/to/your/folder:/tmp
APPTAINER_COMMAND=

# Metadata must be in TSV format
# Manifest must be in CSV format
# For multiple run, seperate each run manifest by a comma (,)
METADATA_FILE_PATH=
MANIFEST_FILE_PATH=

# Leave empty to use system's default  (/tmp)
# DO NOT SPECIFY IF YOU ARE USING APPTAINER COMMAND
TEMPORARY_DIRECTORY=

########################## 
#  Step 1 : Data Import  #
##########################

# PLACEHOLDER for single end support DO NOT CHANGE THIS, ONLY PAIRED IS SUPPORTED
DATA_TYPE=paired

# Number of sequences to use to generate quality plots (default: 10000)
p_n=10000

# Launch Figaro program to predict correct trimming positions
# This program will NEVER affect your reads, it is using reads copies.
RUN_FIGARO=true

# Will substract the longest sequence length by this number
# This will make sure every reads are the same length
# NOTE : This will NOT affect your reads, only the cpies
trim_offset=2

# size must EXCLUDE the primers, ff amplicon length is variable, use the longest length expected
# If you want to test different amplicon size, you can input multiple values (separate them by ,)
# NOTE: each amplicon size takes approximately 40s to compute
f_amplicon_size=368,370,372,374,376,378,380
f_forward_primer_len=20
f_reverse_primer_len=18

# 12 is default value for overlap in Qiime2
f_min_overlap=12

# If true, will delete the exportation file to save disk space (results will be kept)
CLEAN_FIGARO_OUTPUT=true

#########################
#  Cutadapt (Optional)  #
#########################
# This step is done during step 1.5 and step 2

RUN_CUTADAPT=false
forward_trim_param=--p-front-f
reverse_trim_param=--p-front-r

forward_primer=GTGYCAGCMGCCGCGGTAA
reverse_primer=CCGYCAATTYMTTTRAGTTT

p_discard_untrimmed=true

# if true, will force the step to stop just after cutadapt
# Useful for debugging and accessing CutAdapt qzv files
CA_FORCE_INTERRUPTION=false

######################################################
#  Step 1.5 : Dada2 Denoising Parameters Evaluation  #
######################################################

# This step is design to work with a single manifest file
# Manifest must be in CSV format
EVAL_MANIFEST_FILE_PATH=

# if your data is single-end, only p_trim_left_f, p_trunc_len_f and p_max_ee_f will be used in trimming

# Use 0 to bypass evaluation (will just denoise all samples)
DENOISE_EVALUATION_SAMPLE_SIZE=5
TESTFILE_PATH=
# if true, will generate a new random manifest. even if one already exists
# if false, will use the $ANALYSIS_NAME.eval_manifest.temp as subset
FORCE_RESAMPLING=false

# If true, will stop the step after generating $ANALYSIS_NAME.eval_manifest.temp
# Nothing else will be generated until DRY_RUN is switched to false again
DRY_RUN=false

################################
#   Step 2 : Dada2 Denoising   #
################################

# NOT FOR STEP 1.5 (YOU MUST USE TESTFILE FOR STEP 1.5)

# Number of denoising job to launch simultaneously
# Each job will use NB_THREADS / job count
# For best result, your number of job should be a multiple of your NB_THREADS
# Ex: 3 jobs should have 9, 12, 15, etc. NB_THREADS so each job have the same number of threads
# If 1 is used, all job will run sequentially (which will be slower that having multiple jobs)  
CONCURRENT_JOBS=1

# Use 0 to deactivate parameters (should be 0 if you used CutAdapt)
p_trim_left_f=19
p_trim_left_r=20

# Use 0 to deactivate parameters
# If you have multiple run, you must input a value for each of them
# seperate them by a comma (ex 234,235,223)
# They must be in the same order then your manifest list
p_trunc_len_f=237
p_trunc_len_r=209

p_max_ee_f=2
p_max_ee_r=2
p_trunc_q=2
p_n_reads_learn=1000000 

p_chimera_method=consensus
p_min_fold_parent_over_abundance=1.0

###########################
# Step 2.5 : Run Merging  #
###########################


# If true, will proceed with merging even if runs are incompatible (different denoising parameters)
# NOT RECOMMENDED
IGNORE_INCOMPATIBILITY=false



#####################################
# Step 3 : Feature Table filtering  #
#####################################

# FUTURE DEV: REPLACE OR ADD AUTO CALCULATION ACCORDING TO VISUALIZATION DATA
# Use 0 to disable
#freq_threshold=0.0005
p_min_frequency=16


# IDEM ^^^^
# Use 0 to disable
#sample_threshold=0
p_min_samples=0

###############################
# Step 4 : Denovo Clustering  #
###############################

# Must be between ]0 , 1.0]
# Use NA to skip denovo clustering (you must still launch step 4)
p_perc_identity=NA
 
##################################
# Step 5 : Classifier Training   #
##################################

# Only Specify these if you want to train the classifier with your database
# It's recommended to use the same name (different extension) for the fasta and the tax file
# The classifier output name must have the .qza extension

#FASTA_DATABASE_PATH=
#TAXO_DATABASE_PATH=
SEQS_QZA_PATH=
TAXO_QZA_PATH=
CLASSIFIER_OUTPUT_NAME=

#################################
# Step 6 : Taxonomy Assignment  #
#################################

# Only specify this if you skipped step 5
CLASSIFIER_DATABASE_PATH=

# Possible value [0, 1]
p_confidence=0.7

############################
# Step 7 : Taxa Filtering  #
############################

# Filter samples according to specific metadata
# ex "[subject]='subject-1' AND NOT [body-site]='gut'"
# ex "[body-site]='gut' OR [reported-antibiotic-usage]='Yes'"
# ex "[body-site] IN ('left palm', 'right palm')"
# Leave "" to ignore
p_where=""

# Never use space in the list, only comma
# p_exclude remove unwanted taxe and p_include keep only specified taxa
# You can use both option to exclude parts of the inclusion
# If both are empty, taxa filtering will be skipped
p_include=bacteria,archaea
p_exclude=eukaryota,mitochondria,chloroplast

# Must be exact or contains (default)
p_mode=contains

# Will also be used in step 8 and 10  
GENERATE_PHYLOGENY=false

# RAREFACTION OVERRIDE
# true, false or both
# if you activate this option, you can ignore the next sections, skip step 8 and 9
# Use "both" without the quotes to run both with and without rarefaction in a single run
SKIP_RAREFACTION=both
##########################################
#   Step 8 : Alpha rarefaction plotting  #
##########################################

p_max_depth=8000
p_steps=10
p_iterations=10
# Use this format: observed_features,shannon
# You can also leave this blank to use Qiime2 default metrics (observed_features,shannon)
# IMPORTANT: This is NOT the metrics for step 10, this is only for the rarefaction curve
p_metrics=observed_features,shannon

#############################
# Step 9 : Data Rarefaction #
#############################

p_sampling_depth=10000

########################
#   Step 10 : Metrics  #
########################

alpha_metrics=shannon,simpson,observed_features,chao1,pielou_e
beta_metrics=braycurtis,jaccard

# Relevent only if GENERATE_PHYLOGENY is activated
alpha_metrics_phylo=faith_pd
beta_metrics_phylo=weighted_unifrac,weighted_normalized_unifrac,generalized_unifrac,unweighted_unifrac

######################
#   Step 11 : Export #
######################


## FUNGuild specific options (Fungal ITS Only)
# To use FUNGuild, Guilds_v1.1.py must be available in your path
# Recommended FUNGuild version : https://github.com/Patg13/FUNGuild
GENERATE_FUNGUILD=false
# Enter remote_fungi to use remote fungi database (http://stbates.org/funguild_db.php)
# You can also specify a local database path
# Database must be downloaded with the provided bash script in https://github.com/Patg13/FUNGuild
FUNGUILD_DATABASE_PATH=

# Path to the result extraction form (in tsv format)
EXTRACTION_FORM_PATH=

## ANCOM specific options
GENERATE_ANCOM=false
# Collapse table at genus level (6)
p_level=6

# Depend on your metadata
# Specify each target column seperated by a comma
# Ex: Col1,Col2,Col3,Col4
# There will be one ANCOM by column
m_metadata_column=
