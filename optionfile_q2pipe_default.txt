#############################
#                           #
#     Q2Pipe Option file    #
# Designed for Q2Pipe V0.96 #
#                           #
#############################


################################
#  Common Analysis Parameters  #
################################

ANALYSIS_NAME=BASIC_TEST
NB_THREADS=8

# Threads fine-tuning
CLASSIFIER_NB_THREADS=2

# Leave empty if you don't use apptainer image to launch Qiime2
# To define a different temporary folder, add -B /path/to/your/folder:/tmp
# TMPDIR inside the container MUST point to /tmp at all times. DO NOT CHANGE THIS
# Also make sure that the TEMPORARY_DIRECTORY variable point to the same folder
# Q2Pipe can also use the TMPDIR environment variable if set
APPTAINER_COMMAND=

# Metadata must be in TSV format
# Manifest must be in CSV format
# For multiple run, seperate each run manifest by a comma (,)
METADATA_FILE_PATH=
MANIFEST_FILE_PATH=

# Leave empty to use system's TMPDIR variable (fallback on /tmp if not set)
# If you are using apptainer and want to define a different temp folder
# you must also add '-B /path/to/temp:/tmp' to the apptainer command definition
TEMPORARY_DIRECTORY=

########################## 
#  Step 1 : Data Import  #
##########################

# PLACEHOLDER for single end support DO NOT CHANGE THIS, ONLY PAIRED IS SUPPORTED
DATA_TYPE=paired

# Number of sequences to use to generate quality plots (default: 10000)
p_n=10000

### FALCO ###

# Launch Falco analysis on samples (similar to fastqc but faster implementation)
# This program will NEVER affect your reads, it is using reads copies
RUN_FALCO=true

# Trim the end of the reads to reduce false positive on Falco FAIL detection
# Use 0 to analyse the complete sequence (not recommended as you many of your sample will fail
# screening because of the low-quality ends whit Illumina data
# Use 0 to disable the trimming
falco_right_trim=280

# Create a combined R1 file and a combined R2 file and run it through Falco
# Should give similar results to Qiime2 import, but could help flag entire run problems
# Will take more time to run and take more disk space
FALCO_COMBINED_RUN=true

# If true, will delete the exportation file to save disk space (results will be kept)
CLEAN_FALCO_OUTPUT=true

### FIGARO ###

# Launch Figaro program to predict correct trimming positions
# This program will NEVER affect your reads, it is using reads copies.
RUN_FIGARO=true

# Will substract the longest sequence length by this number
# This will make sure every reads are the same length
# NOTE : This will NOT affect your reads, only the cpies
figaro_trim_offset=2

# size must EXCLUDE the primers, ff amplicon length is variable, use the longest length expected
# If you want to test different amplicon size, you can input multiple values (separate them by ,)
# NOTE: each amplicon size takes approximately 40s to compute
f_amplicon_size=368,370,372,374,376,378,380
f_forward_primer_len=20
f_reverse_primer_len=18

# 12 is default value for overlap in Qiime2
f_min_overlap=12

# If true, will delete the exportation file to save disk space (results will be kept)
CLEAN_FIGARO_OUTPUT=true

#########################
#  Cutadapt (Optional)  #
#########################
# This step is done during step 1.5 and step 2

RUN_CUTADAPT=false
forward_trim_param=--p-front-f
reverse_trim_param=--p-front-r

forward_primer=GTGYCAGCMGCCGCGGTAA
reverse_primer=CCGYCAATTYMTTTRAGTTT

p_discard_untrimmed=true

# Ratio of error in the adapter recognition
# The actual error rate is computed as the number of errors in the match 
# divided by the length of the matching part of the adapter
# Ex: an adapter match of length 8 containing 1 error has an error rate of 1/8=0.125
p_error_rate=0.1

# if true, will force the step to stop just after cutadapt
# Useful for debugging and accessing CutAdapt qzv files
CA_FORCE_INTERRUPTION=false

################################
#   Step 2 : Dada2 Denoising   #
################################

# NOT FOR STEP 1.5 (YOU MUST USE TESTFILE FOR STEP 1.5)

# Number of denoising job to launch simultaneously
# Each job will use NB_THREADS / job count
# For best result, your number of job should be a multiple of your NB_THREADS
# Ex: 3 jobs should have 9, 12, 15, etc. NB_THREADS so each job have the same number of threads
# If 1 is used, all job will run sequentially (which will be slower that having multiple jobs)  
CONCURRENT_JOBS=1

# Use 0 to deactivate parameters (should be 0 if you used CutAdapt)
p_trim_left_f=19
p_trim_left_r=20

# Use 0 to deactivate parameters
# If you have multiple run, you must input a value for each of them
# seperate them by a comma (ex 234,235,223)
# They must be in the same order then your manifest list
p_trunc_len_f=237
p_trunc_len_r=209

p_max_ee_f=2
p_max_ee_r=2
p_trunc_q=2
p_n_reads_learn=1000000 

p_chimera_method=consensus
p_min_fold_parent_over_abundance=1.0

###########################
# Step 2.5 : Run Merging  #
###########################


# If true, will proceed with merging even if runs are incompatible (different denoising parameters)
# NOT RECOMMENDED
IGNORE_INCOMPATIBILITY=false



#####################################
# Step 3 : Feature Table filtering  #
#####################################

# FUTURE DEV: REPLACE OR ADD AUTO CALCULATION ACCORDING TO VISUALIZATION DATA
# Use 0 to disable
#freq_threshold=0.0005
p_min_frequency=16


# IDEM ^^^^
# Use 0 to disable
#sample_threshold=0
p_min_samples=0

###############################
# Step 4 : Denovo Clustering  #
###############################

# Must be between ]0 , 1.0]
# Use NA to skip denovo clustering (you must still launch step 4)
p_perc_identity=NA
 

#################################
# Step 5 : Taxonomy Assignment  #
#################################

# Only specify this if you skipped step 5
CLASSIFIER_DATABASE_PATH=

# Possible value [0, 1]
p_confidence=0.7

############################
# Step 6 : Taxa Filtering  #
############################

# Filter samples according to specific metadata
# ex "[subject]='subject-1' AND NOT [body-site]='gut'"
# ex "[body-site]='gut' OR [reported-antibiotic-usage]='Yes'"
# ex "[body-site] IN ('left palm', 'right palm')"
# Leave "" to ignore
p_where=""

# Never use space in the list, only comma
# p_exclude remove unwanted taxe and p_include keep only specified taxa
# You can use both option to exclude parts of the inclusion
# If both are empty, taxa filtering will be skipped
p_include=bacteria,archaea
p_exclude=eukaryota,mitochondria,chloroplast

# Must be exact or contains (default)
p_mode=contains

# Will also be used in step 8 and 10  
GENERATE_PHYLOGENY=false

# RAREFACTION OVERRIDE
# true, false or both
# if you activate this option, you can ignore the next sections, skip step 8 and 9
# Use "both" without the quotes to run both with and without rarefaction in a single run
SKIP_RAREFACTION=both

# rarefaction or normalization
RAREFACTION_METHOD=rarefaction

##########################################
#   Step 7 : Alpha rarefaction plotting  #
##########################################

# Common options between Normalization and Rarefaction
p_max_depth=8000
p_steps=10
p_iterations=10

# Rarefaction metrics
# Use this format: observed_features,shannon
# Qiime2 default metrics (observed_features,shannon)
# IMPORTANT: This is NOT the metrics for step 10, this is only for the rarefaction curve
p_metrics=observed_features,shannon

# Normalization metric (choice: richness shannon simpson invsimpson)
# WARNING: Normalization does NOT support multiple metrics
p_normalization_metric=richness

#############################
# Step 8 : Data Rarefaction #
#############################

# If rarefaction method is normalization, use p_sampling_depth as Cmin
p_sampling_depth=10000

# Random integer seed to use for rarefaction/normalization step
# Use $RANDOM for random seed at each execution
# Using the same seed will lead to the same result.
p_random_seed=$RANDOM

########################
#   Step 9 : Metrics   #
########################

alpha_metrics=shannon,simpson,observed_features,chao1,pielou_e
beta_metrics=braycurtis,jaccard

# Relevent only if GENERATE_PHYLOGENY is activated
alpha_metrics_phylo=faith_pd
beta_metrics_phylo=weighted_unifrac,weighted_normalized_unifrac,generalized_unifrac,unweighted_unifrac

######################
#   Step 10 : Export #
######################


## FUNGuild specific options (Fungal ITS Only)
# To use FUNGuild, Guilds_v1.1.py must be available in your path
# Recommended FUNGuild version : https://github.com/Patg13/FUNGuild
GENERATE_FUNGUILD=false
# Enter remote_fungi to use remote fungi database (http://stbates.org/funguild_db.php)
# You can also specify a local database path
# Database must be downloaded with the provided bash script in https://github.com/Patg13/FUNGuild
FUNGUILD_DATABASE_PATH=

# Path to the result extraction form (in tsv format)
EXTRACTION_FORM_PATH=

## ANCOM specific options
GENERATE_ANCOM=false
# Collapse table at genus level (6)
p_level=6

# Depend on your metadata
# Specify each target column seperated by a comma
# Ex: Col1,Col2,Col3,Col4
# There will be one ANCOM by column
m_metadata_column=
